{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "The block of codes below utilize Linear Regression Model as implemented in Scikit-learn to predict eigen values \n",
    "of HSE06 quality using the elementwise-orbital contribution of the atoms to the corresponding eigenstates in \n",
    "PBE calculations.\n",
    "### Note:\n",
    "We will require two .tar.gz files for running this notebook namely, specific_concatenations.tar.gz and \n",
    "atom_sum_csv_files.tar.gz. As size of both of these tarballs exceed 25 MB, I couldn't directly upload them in\n",
    "the github. However you could access these tarballs from dropbox (dropbox/ML_eigenshift) or \n",
    "from the Hyperion cluster (/work/sutton-lab/ml_eigenshift/krr/concatenated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules:\n",
    "We will require following modules for using the linear model. Don't forget to use eg. pip install numpy and so on\n",
    "to install the missing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "import pylab as pl\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are defining three functions below. Please also see the comments above each functions for more details. \n",
    "First couple of functions namely 'two_csv_train_test', and 'single_csv_train_test' prepare the numpy arrays\n",
    "necessary for training and testing the linear regression model. The last function named 'plot' is to get the\n",
    "scatter plots using the outputs of the first two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions two_csv_train_test takes 2 arguments. First is the path of csv file used for training while the\n",
    "# second is the path of csv for testing. The default input columns are [1s,2s,.....,6p,PBE_EF]\n",
    "#It returns four numpy arrays in following order: 1. train_input 2. test_input 3. train_target 4. test_target. \n",
    "# Note these in order are the arguments for function plot\n",
    "\n",
    "def two_csv_train_test(path_csv_train,path_csv_test):\n",
    "    train_csv_to_df=pd.read_csv(path_csv_train) # eg. concat_dir+'Ca1O1.csv'\n",
    "    columns_input=[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,20]\n",
    "    train_input_feature=train_csv_to_df.iloc[:,columns_input].values\n",
    "    train_target_feature=train_csv_to_df.iloc[:,-1].values\n",
    "    #print(train_input_feature)\n",
    "    #print(train_target_feature)\n",
    "    test_csv_to_df=pd.read_csv(path_csv_test) # eg. all_files_dir+'Ag2O1.csv'\n",
    "    test_input_feature=test_csv_to_df.iloc[:,columns_input].values\n",
    "    test_target_feature=test_csv_to_df.iloc[:,-1].values\n",
    "    return train_input_feature,test_input_feature,train_target_feature,test_target_feature\n",
    "\n",
    "# Functions single_csv_train_test takes 2 arguments. First is the path of the csv file used for both training and \n",
    "# testing. Second is the fraction of train/test split (recommended = 0.8). It returns four numpy arrays in following \n",
    "# order: train_input, test_input, train_target, test_target. Note these in order are the arguments for function plot\n",
    "\n",
    "def single_csv_train_test(path_csv_file,split_frac): \n",
    "    ag2o_csv_to_df=pd.read_csv(path_csv_file) #eg. all_files_dir+'Ag2O1.csv'\n",
    "    columns_input=[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,20]\n",
    "    actual_columns=columns_input+[-1]\n",
    "    #ag2o_input_feature=ag2o_csv_to_df.iloc[:,[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,20,-1]].values\n",
    "    ag2o_input_feature=ag2o_csv_to_df.iloc[:,actual_columns].values\n",
    "    random_indices=ag2o_input_feature[np.random.randint(ag2o_input_feature.shape[0], size=ag2o_input_feature.shape[0]), :]\n",
    "    siz_x,siz_yy=np.shape(random_indices)\n",
    "    split=int(siz_x*split_frac)\n",
    "    array1= random_indices[:split,:] # indexing/selection of the 80%\n",
    "    array2 = random_indices[split:,:]\n",
    "    return array1[:, :-1],array2[:, :-1],array1[:,-1],array2[:,-1]\n",
    "\n",
    "# As suggested above function plot is used for generating scatter plot it takes four numpy arrays in following order as\n",
    "# input: 1. train_input 2. test_input 3. train_target 4. test_target . It returns plot as plt, train_mae, and test_mae\n",
    "# We can save, display the plot obtained from here. do not forget to close the plot after calling it. eg. plt.close()\n",
    "\n",
    "def plot(x,p,y,q):\n",
    "    clf=linear_model.LinearRegression()\n",
    "    y2=clf.fit(x,y)\n",
    "    y_hat2=clf.predict(x)\n",
    "    q_hat2=clf.predict(p)\n",
    "    train_mae=mean_absolute_error(y,y_hat2)\n",
    "    test_mae=mean_absolute_error(q,q_hat2)\n",
    "    #print(train_mae,test_mae)\n",
    "    a=np.min(y)\n",
    "    b=np.max(y)\n",
    "    #print(a,b)\n",
    "    diag_array=np.linspace(a, b, num=1000)\n",
    "    aspect_ratio=(3,5)\n",
    "    left_margin=0.3 # Adjust it for your best results\n",
    "    #plt.ylim(band_min,band_max)\n",
    "    #plt.xlim(xmin,xmax)\n",
    "    plt.scatter(diag_array,diag_array,s=0.5,color='black',alpha=1.0)\n",
    "    plt.scatter(y,y_hat2,color='blue',alpha=0.2,label='train')\n",
    "    plt.scatter(q,q_hat2,color='red',alpha=0.2,label='test')\n",
    "    plt.xlabel(\"DFT shift (in eV)\",fontsize=14)\n",
    "    plt.ylabel(\"predicted shift (in eV)\",fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    #plt.axhline(y=0.0,color='purple',linestyle='--',linewidth=1.5)\n",
    "    plt.subplots_adjust(left=left_margin)\n",
    "    plt.legend(fontsize='10',ncol=1, loc='best',frameon=False)\n",
    "    #plt.savefig('_train='+str(train_mae)+'_test'+str(test_mae)+'.pdf',dpi=80)\n",
    "    #plt.show()\n",
    "    return plt,train_mae,test_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here provide the location of the csv files. These csv files provide the information of mostly PBE calculations.\n",
    "It displays sum of elementwise-orbital contribution to eigen states along with the eigenvalues, shift of eigenvalue\n",
    "wrt the fermi level, corresponding eigen values and shift from HSE06 calculations and finally the shift between PBE and\n",
    "HSE06 eigenvalues at each eigenstates. The csv files corresponding to each compound are found in folder atom_sum_csv_files\n",
    "or its corresponding tarball. The folder specific_concatenations or its corresponding tarball consists of the\n",
    "concatenation of various files mostly intuitive by their name. Note again as stated in the first block that the \n",
    "folders or tarballs mentioned above are not found here in github as they exceed 25 MB size. Look for dropbox\n",
    "or Hyperion cluster to access them as detailed in first block above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "cwd=os.getcwd()  # gives the path of the current working directory\n",
    "list_cwd=os.listdir(cwd)\n",
    "#print(list_cwd)\n",
    "import tarfile\n",
    "tar_files=['specific_concatenations','atom_sum_csv_files']\n",
    "for entries in tar_files:\n",
    "    if entries in tar_files not in list_cwd:\n",
    "        file = tarfile.open(str(entries)+'.tar.gz')  \n",
    "        # extracting file\n",
    "        file.extractall()\n",
    "        file.close()\n",
    "\n",
    "#path of the directories containing csv file of all systems and specific concatenations\n",
    "concat_dir=os.path.join(cwd,'specific_concatenations/')\n",
    "all_files_dir=os.path.join(cwd,'atom_sum_csv_files/')\n",
    "concat_files_list=os.listdir(concat_dir)\n",
    "all_files_list=os.listdir(all_files_dir)\n",
    "\n",
    "#print(cwd)\n",
    "#print(concat_dir)\n",
    "#print(concat_files_list)\n",
    "#print(all_files_dir)\n",
    "#print(all_files_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below utilizes functions defined above to show/save the plot. Don't forget to use plt.savefig(\"name.pdf\",dpi=80)\n",
    "to save the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "x,p,y,q=single_csv_train_test(all_files_dir+'Ag2O1.csv',0.8)\n",
    "plt,train_mae,test_mae=plot(x,p,y,q)\n",
    "print(train_mae,test_mae)\n",
    "plt.show()\n",
    "plt.close()\n",
    "'''\n",
    "x,p,y,q=two_csv_train_test(concat_dir+'Ca1O1.csv',all_files_dir+'Ag2O1.csv')\n",
    "plt,train_mae,test_mae=plot(x,p,y,q)\n",
    "print(train_mae,test_mae)\n",
    "plt.show()\n",
    "plt.close()\n",
    "'''\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
